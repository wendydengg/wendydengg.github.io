<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://wendydengg.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://wendydengg.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-17T05:12:33+00:00</updated><id>https://wendydengg.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Looking Forward</title><link href="https://wendydengg.github.io/blog/2024/looking-forward/" rel="alternate" type="text/html" title="Looking Forward"/><published>2024-12-16T00:32:13+00:00</published><updated>2024-12-16T00:32:13+00:00</updated><id>https://wendydengg.github.io/blog/2024/looking-forward</id><content type="html" xml:base="https://wendydengg.github.io/blog/2024/looking-forward/"><![CDATA[ <p>Concrete steps after Digital Humanities:</p> <ol> <li>I have always been interested in text data and linguistics, and I have been thinking about doing research perhaps with Professor CCB in natural language processing (NLP), but now I want to understand how we can apply NLP to different fields like Humanities while navigating ethics issues – this will probably be my research project for next semester</li> <li>I’ve been recommended to read <em>The Message</em> by Ta-Nehisi Coates, which explores the power of stories to shape reality and the importance of embracing difficult truths. Since this course has led me to think how subjective our “data” acually is since it is told by the lens of one person, I want to further explore what it means to experience a “reality” told through the lens of another person</li> <li>I want to take CIS 6300 to further my understanding of NLP, specifically on how to apply NLP to existing problem domains and conduct research in NLP</li> </ol>]]></content><author><name></name></author><category term="Digital_Humanities"/><summary type="html"><![CDATA[Concrete steps after Digital Humanities: I have always been interested in text data and linguistics, and I have been thinking about doing research perhaps with Professor CCB in natural language processing (NLP), but now I want to understand how we can apply NLP to different fields like Humanities while navigating ethics issues – this will probably be my research project for next semester I’ve been recommended to read The Message by Ta-Nehisi Coates, which explores the power of stories to shape reality and the importance of embracing difficult truths. Since this course has led me to think how subjective our “data” acually is since it is told by the lens of one person, I want to further explore what it means to experience a “reality” told through the lens of another person I want to take CIS 6300 to further my understanding of NLP, specifically on how to apply NLP to existing problem domains and conduct research in NLP]]></summary></entry><entry><title type="html">Reflection on Two Main Class Projects</title><link href="https://wendydengg.github.io/blog/2024/reflection-class-projects/" rel="alternate" type="text/html" title="Reflection on Two Main Class Projects"/><published>2024-12-16T00:32:13+00:00</published><updated>2024-12-16T00:32:13+00:00</updated><id>https://wendydengg.github.io/blog/2024/reflection-class-projects</id><content type="html" xml:base="https://wendydengg.github.io/blog/2024/reflection-class-projects/"><![CDATA[ <p>The overarching theme of our two main projects of Printing in Prisons website and the collaborative project in the Education Commons (EC) was introduced during our class on October 7th, during which we learned about the storage problem of digital assets as well as the effort to humanize data.</p> <p>The storage problem refers to the dilemma that as digital forms of information increase, there is also an increasing demand for larger storage space online as well as physically. This presented a new type of challenge that troubled people who initially thought of digitalization as a way to mitigate the fragility of materials like paper. Moreover, the labor that goes into digitalization is often forgotten or uncredited, although the intent of the creator to preserve information in its original form is usually clear. For example, the project <a href="https://www.acrosswalls.org/section/introduction/">Across Walls</a> presents images of prisoners without names and description, and the site also lacks institutional affilation and funding, but it is clear that this project is meant to humanize those prisoners but simply could not or did not find more informations about them due to funding issues.</p> <p>In an reference to the reading/video in our very first class, Giorgia Lupi emphasizes the importance to allow people to “interact with information through data visualization and through building interactive experiences with these visualizations” (<a href="https://www.youtube.com/watch?v=IYRhCZ0vvFQ">Finding Humanity in Data</a>). Thus, in an effort to showcase historical information through visual and interactive experiences and to avoid the storage problem, we find creative ways to search for and document our findings through these two main class projects.</p> <p>The <a href="https://printinginprisons.org/">Printing in Prisons</a> was created by Professor Trettien as an effort to uncover the lives of prisoners in the Eastern State Penitentiary (ESP) through the stories told in newspapers, the Umpire, printed in the ESP. As opposed to the Across Walls project, Printing in Prisons tells stories about the prisoners directly from their own lens, and to do so, we picked a topic of our interest and read as much information as possible about it through an archive of the Umpire. I picked the topic of Women in the ESP because they were not part of the print shop in printing those newspapers and were heavily outnumbered by male inmates, but they were an important part of the ESP as evident through the mentions of female embroidery and knitting works, as well as how “female beauty” made the male inmates feel refreshed. Throughout my writing, I constantly reminded myself to simply be a person who collects and synthesizes information as unfiltered as possible in order to preserve the original meaning of the text.</p> <div style="text-align: center;"> <img src="/assets/img/printing-in-prisons.jpg" alt="Women in Prison Blog" style="width: 70%; height: auto;"/> </div> <p>Similarly, our <a href="/blog/2024/fabrication-workshop/">project in the EC</a> also emphasizes the purpose of displaying information in its unfiltered, original intent. As part of the fabrication group, we had access to the printing machine and was intrigued by how words and figures can be etched into different materials. Since the articles in the Umpire emcompass a lot of topics ranging from poems to baseball to religion, we decided to focus on how religion is a strong prevalence in the Umpire and the minds of prisoners. Keeping in mind of the storage problem of digital assets, this project allowed us to create something physical that captures the essense of a part of life in the ESP.</p> <div style="text-align: center;"> <img src="/assets/img/final-histogram.jpg" alt="Printed Histogram" style="width: 30%; height: auto;"/> </div> <p>Lastly, I also went to a <a href="/blog/2024/web-scraping-workshop/">workshop at Penn</a> that taught us how to use the Python library BeautifulSoup to scrape the web as well as how to do so ethically. Through the readings and class projects, I realized that issues such as the storage problem and the inability to represent moments of life in history beyond mere words stemmed from the fact that there are a plethora amount of information on the web, but most of them are not synthesized or compacted to create meaning. Through techniques like web-scraping, we can find information on the web that are only relevant to our topic of interest. For example, we could use relevant keywords to find more information about women in prison or how religion manifested itself in writings by the inmates, given that those information are publically available or able to be scraped with the consent of the web owner.</p> <div style="text-align: center;"> <img src="/assets/img/web-scraping-ipynb.jpg" alt="Web Scraping Notebook" style="width: 75%; height: auto;"/> </div> <div style="text-align: center;"> <img src="/assets/img/web-scraping-rdds.jpg" alt="Web Scraping at the Research Data &amp; Digital Scholarship (RDDS) Exchange at Van Pelt" style="width: 20%; height: auto;"/> </div>]]></content><author><name></name></author><category term="Digital_Humanities"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Statement on Digital Humanities, Fall 2024</title><link href="https://wendydengg.github.io/blog/2024/statement-on-coursework/" rel="alternate" type="text/html" title="Statement on Digital Humanities, Fall 2024"/><published>2024-12-16T00:32:13+00:00</published><updated>2024-12-16T00:32:13+00:00</updated><id>https://wendydengg.github.io/blog/2024/statement-on-coursework</id><content type="html" xml:base="https://wendydengg.github.io/blog/2024/statement-on-coursework/"><![CDATA[ <p>The process of working with humanities data is fundamentally different from other disciplines. In fact, As Rawson and Muñoz argue in their seminal work “<a href="https://www.jstor.org/stable/pdf/10.5749/j.ctvg251hk.26.pdf?acceptTC=true&amp;coverpage=false"><em>Against Cleaning</em></a>,” researchers working in the humanities domain should be hesitant to call such knowledge “data” and must approach data with a nuanced understanding that goes beyond simple digitization or transcription. Specifically, humanities data is not about creating a clean, uniform dataset, but about preserving the rich, complex narratives embedded within historical artifacts. Simply gathering “data” for humanities research is analogous to reading a line of text without knowing the context surrounding it. Although technology like AI has advanced to the point of understanding and generating text from context, it would be difficult to do so for humanities research due to the nature that most of the historical information is stored in physical objects and the fact that these types of “data” simply cannot be generated, or else its historical context would be lost. Throughout this semester, we’ve engaged in several projects to experience what it’s like to gather and synthesize information for humanities research and to create physical representations of history, with the themes of humanizing data and retelling history (themes were also explored in my <a href="/blog/2024/reflection-class-projects/">reflection on the two main course projects</a>).</p> <p>One of our first projects was to generate data and metadata on articles pertaining to the Reformatory Records using Tesseract, a tool to extract text from images. From searching through the Reformatory Records on the <a href="https://digitalarchives.powerlibrary.org/psa/">Pennsylvania State Archieves Power Library</a> to extracting the information needed through Tesseract, we experienced first-hand how difficult it is to transform material information such as text on paper to digital information on the web. Not only is it that there are hundreds of pages to go through, nor the fact that those pages were stored on a website that houses couple thousands of similar collections, causing difficulties in simply rendering the pages, this process also requires us to be very meticulous in tranferring the data to digital format to ensure that text is not lost nor translated incorrectly. After transferring the text, we also noted down the metadata surrounding the current text, including page number, release date, volume, and tags, in order to capture the full context of the information we have just extracted. This is important because like Professor Trettien and Professor Lesser have said in their essay, “Material / digital,” the metadata is just as important as the data itself, but “the process of linking and uploading these photos strips them of the information most relevant to understanding them as material objects in themselves, namely the Exif (exchangeable image file format) metadata” (20. Material / digital, 414), which is why it is of ulmost importance to note down the metadata manually. The <a href="blog/2024/web-scraping-workshop/">Web-Scraping Workshop</a> that I have attended at the Research Data &amp; Digital Scholarship (RDDS) Exchange at Van Pelt underscored this challenge. It introduced us to a powerful tool that can gather information on the web that is publically available or available through the consent of its owner, but with text on paper or information that is stored behind a paywall, such as with most historical content, web-scraping cannot be easily utilized. As Rawson and Muñoz suggest, the goal is not to create a perfectly “cleaned” dataset, but to build an index that preserves the diversity and contextual richness of the original materials, which is why manual curation of such data is still be best way to gather information in order to preserve its history.</p> <div style="text-align: center;"> <img src="/assets/img/reformatory-records-1.jpg" alt="Reformatory Records 1" style="width: 30%; height: auto;"/> </div> <div style="text-align: center;"> <img src="/assets/img/reformatory-records-2.jpg" alt="Reformatory Records 2" style="width: 30%; height: auto;"/> </div> <p>I have detailed my reflection on the two main course projects on my contribution to the Printing in Prisons project and the collaborative workshop in the Education Commons in a <a href="/blog/2024/reflection-class-projects/">separate article</a>, but the message from those projects stayed consistent: to understand what it’s like to be a researcher in digital humanities from gathering and synthesizing data that is not easily accessible on the web or even in paper, to building a story out of it. In particular, the Printing in Prisons project demanded that we look thoroughly through the articles to extract traces of life pertinent to our chosen topic in order to understand the human experiences beyond words printed onto papers. We weren’t just transcribing text; we were creating a nuanced representation of historical experiences either through written format or a symbolic representation.</p> <p>Coming into this class, I expected a straightforward process of digitalizing and analyzing humanities data as a student studying data science, but I did not expect the meticulous process that goes behind carefully understanding the context of the data and the lives that those data represent. In fact, I even catch myself hesitating on saying the word “data” because the information we gathered were not facts; they were stories told through lens of individuals, shaped my their experiences, and retold through our own interpretations. Now, I recognize digital humanities as a interpretive practice that requires us to be critically aware of how we represent and transform information, whether that information pertains to the humanities domain or any other domain, and I will carry that lesson in mind through my future career as I work with “data.”</p>]]></content><author><name></name></author><category term="Digital_Humanities"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Fabrication Workshop</title><link href="https://wendydengg.github.io/blog/2024/fabrication-workshop/" rel="alternate" type="text/html" title="Fabrication Workshop"/><published>2024-12-06T00:32:13+00:00</published><updated>2024-12-06T00:32:13+00:00</updated><id>https://wendydengg.github.io/blog/2024/fabrication-workshop</id><content type="html" xml:base="https://wendydengg.github.io/blog/2024/fabrication-workshop/"><![CDATA[<p>Over the past two weeks, we brainstormed on ways to represent data in the Umpire through a laser cutter.</p> <p>Given the mass amount of data regarding the Umpire, it is difficult to determine a concise definition and meaning by first glance. Since each entry in our dataset is categorized by topics such as baseball, ESP league, and religion, we analyzed each topic in depth and decided to focus on religion because we were interested in ways that prisoners remained hopeful during times of loneliness and despair. Another reason is that we already know baseball is a recurring theme in the Umpire, so we wanted to bring a new perspective. Thus, our goal was to use a laser cutter to create a physical, tangible representation of religion in the Umpire. The resulting product was a histogram of the frequency of religious words in the Umpire sitting on top of a birds’ eye view of the ESP, the corresponding words for the frequencies were also inscribed onto the histogram.</p> <p>We met multiple times in the EC and on Zoom to discuss and complete this project, and everyone was able to contribute meaningfully to each session due to the role specifications. One of our initial ideas was to create a word cloud out of the frequencies of religious words mentioned in the Umpire, but the resulting prototyped image ended up being too crowded and not aesthetically appealing, not to mention that it would be vert difficult for the laser cutter to replicate such a vision. By iterating through ideas and prototypes and discussing pros and cons of each, we narrowed our final idea down to having a histogram with each bar engraved with its corresponding word related to religion.</p> <p>The acrylic material for the histogram had a reflective finish, so we had another idea to print a poem witten in the ESP as the base of the histogram – a symbol that religious beliefs create a stable foundation for the inmates. However, laser cutting words would again be difficult to achieve, so we ultimately decided to etch a map of the ESP as the base of the histogram to symbolize that the historical information we used emerged from the grounds of the prison.</p> <p>During the presentation, we asked our viewers to be able to see their face reflected in the histogram on the other side of where the words were engraved so that the color-changing property of our acrylic material reflects the dynamism of faith itself.</p> <p>As the Digital Asset Manager, I was present in all meetings in order to provide data analysis. For example, I wrote the code for counting the number of religion-related words using regex, and I also generated the word cloud and histogram as shown below:</p> <div style="display: flex; justify-content: space-between; gap: 20px;"> <img src="/assets/img/word_cloud.jpg" alt="Word Cloud" style="width: 48%; height: auto;"/> <img src="/assets/img/histogram.jpg" alt="Histogram" style="width: 48%; height: auto;"/> </div> <p>And here is the code that I used to create the graphs above:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">re</span>
<span class="kn">import</span> <span class="n">nltk</span>
<span class="kn">from</span> <span class="n">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="n">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">nltk</span><span class="p">.</span><span class="nf">download</span><span class="p">(</span><span class="sh">'</span><span class="s">stopwords</span><span class="sh">'</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">data.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">all_text</span> <span class="o">=</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">].</span><span class="nf">dropna</span><span class="p">())</span>

<span class="n">words</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">findall</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\b[a-zA-Z]+\b</span><span class="sh">'</span><span class="p">,</span> <span class="n">all_text</span><span class="p">.</span><span class="nf">lower</span><span class="p">())</span>

<span class="n">stop_words</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">stopwords</span><span class="p">.</span><span class="nf">words</span><span class="p">(</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">))</span>
<span class="n">filtered_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>

<span class="n">religion_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\b(god|faith|church|bible|prayer|spiritual|religion|holy|worship|christian|muslim|islam|hindu|buddhist|jewish|temple|synagogue|mosque|sacred|divine|belief|ritual|soul|heaven|hell|angel|sin)\b</span><span class="sh">'</span><span class="p">)</span>

<span class="n">religion_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">filtered_words</span> <span class="k">if</span> <span class="n">religion_pattern</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">word</span><span class="p">)]</span>

<span class="n">word_counts</span> <span class="o">=</span> <span class="nc">Counter</span><span class="p">(</span><span class="n">religion_words</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Religion-Related Words and Their Frequencies:</span><span class="sh">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">frequency</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">frequency</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="n">wordcloud</span> <span class="o">=</span> <span class="nc">WordCloud</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">background_color</span><span class="o">=</span><span class="sh">'</span><span class="s">white</span><span class="sh">'</span><span class="p">).</span><span class="nf">generate_from_frequencies</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="sh">'</span><span class="s">bilinear</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Religion-Related Word Cloud</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Repent</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Forgive</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Faith</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Devotion</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Remorse</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">God</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Sin</span><span class="sh">'</span><span class="p">]</span>
<span class="n">frequencies</span> <span class="o">=</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">42</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">130</span><span class="p">,</span> <span class="mi">60</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">frequencies</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">skyblue</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Frequency of Religion-Related Words</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Words</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Frequency</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="Digital_Humanities"/><summary type="html"><![CDATA[Reflection on visualizing history using a laser cutter]]></summary></entry><entry><title type="html">Web-Scraping Workshop</title><link href="https://wendydengg.github.io/blog/2024/web-scraping-workshop/" rel="alternate" type="text/html" title="Web-Scraping Workshop"/><published>2024-09-24T00:32:13+00:00</published><updated>2024-09-24T00:32:13+00:00</updated><id>https://wendydengg.github.io/blog/2024/web-scraping-workshop</id><content type="html" xml:base="https://wendydengg.github.io/blog/2024/web-scraping-workshop/"><![CDATA[<p>Web scraping is a common tool used to quickly and efficiently extract large amounts of data from websites. I attended the Introduction to Web Scraping Workshop by Stephen Hall, a Computer Science librarian at the Research Data &amp; Digital Scholarship (RDDS) Exchange at Van Pelt, introduced us to the Python package BeautifulSoup and some precautions to keep in mind before doing any web-scraping on the website.</p> <h2 id="before-web-scraping">Before Web-Scraping</h2> <p>He started off the presentation by reminding us of the dangers and precautions to keep in mind when doing web-scraping. Specifically, we need to check the terms and services file to see if the owner of the site permits web-scraping. If that is not available, we can inspect the site’s robots.txt file (which is meant to be machine-readable but can also be checked by humans) that tells web crawlers what their permissions are. For example, the New York Times does not allow web-scraping of any of their articles. Web-scraping in itself is not an illegal task, but if done so without the permission of the site owners, it is possible to get into a lot of legal troubles. This is especially an issue when web-scraping is done illegally and dangerously for users with bad intentions as they can introduce a lot of problems to the site owners. For instance, university resources are not allowed to be scrapped because vendors of the universities monitor their sites and will ban the university’s IP address if suspicious activities are found. The bottom line is that if you are unsure about the permissions of a site, don’t perform web-scraping. Below is a list of other key considerations when performing web-scraping:</p> <ul> <li>Had the owner made it publicly and freely available? (if it is behind a paywall, then no)</li> <li>An account is not required to access the data</li> <li>The website should not block scrapers</li> <li>Issues of copyright infringement and plagiarism</li> <li>How are we using the data?</li> <li>Does it have an API? Cuz we should use that instead</li> <li>Most of the sites we wanna scrape… we can’t</li> <li>Penn has an intellectual property manager to handle these types of issues</li> </ul> <h2 id="technical-details">Technical Details</h2> <p>As for the technical details, web-scraping is simply a form of regular expression matching. Regular expressions are a sequence of characters that specifies a pattern to search for in text. It is the backbone of most “find and replace” algorithms, including Ctrl-F. We then performed some simple regex queries over a toy website called https://books.toscrape.com. Below are some examples of regex matching syntax:</p> <ul> <li>‘<em>’ looks for preceding character 0 or more times ab</em>c (a and c with any number of b in b/t)</li> <li>’+’ looks for preceding character 1 or more times ab*c (a and c with at least one b in b/t)</li> <li>’.’ wildcard character a.c (a and c with any single character in b/t)</li> <li>’?’ preceding character may or may not be present in string docx (doc and docx)</li> <li>‘\d’ matches any digit character</li> <li>‘\s’ matches any whitespace character</li> <li>‘[…]{#}’ matches any character in a range, with # number of characters back-to-back</li> <li>‘[A-Za-z0-9]’ any character between A to Z, any b/t a to z, any b/t 0 to 9</li> <li>’()’ sub-catch returns only stuff in that parenthesis, but need to specify which group # in group(#)</li> </ul> <h2 id="digital-humanities-application">Digital Humanities Application</h2> <p>I can see this skill being extremely useful for digital humanities projects, where the historical data is scattered around the web and requires manual checking of the text to ensure validity. For example, if we want to find more data regarding inmates in the Eastern State Penitentiary (ESP), which is sparsely available, we can perform web-scraping over websites that contain all possible information about inmates in Philadelphia and narrow down to those who lived in the ESP. Thank you to the RDDS team at Van Pelt!</p>]]></content><author><name></name></author><category term="Digital_Humanities"/><summary type="html"><![CDATA[Summary of an Introduction to Web Scraping Workshop at the Research Data & Digital Scholarship (RDDS) Exchange at Van Pelt]]></summary></entry></feed>